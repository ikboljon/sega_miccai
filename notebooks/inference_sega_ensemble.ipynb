{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import nrrd\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from einops import  rearrange\n",
    "\n",
    "\n",
    "def get_patient_files(path_to_imgs):\n",
    "\n",
    "    path_to_imgs = pathlib.Path(path_to_imgs)\n",
    "\n",
    "    patients = [p for p in os.listdir(path_to_imgs) if os.path.isdir(path_to_imgs / p)]\n",
    "\n",
    "    paths = []\n",
    "\n",
    "    for p in patients:\n",
    "        path_to_ct = path_to_imgs / p / (p + '_ct.nrrd')\n",
    "        path_to_gt = path_to_imgs / p / (p + '_gt.seg.nrrd')\n",
    "\n",
    "        paths.append((path_to_ct, path_to_gt))\n",
    "    return paths\n",
    "\n",
    "class SegaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, paths_to_samples, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.paths = get_patient_files(paths_to_samples)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "       \n",
    "        sample = dict()\n",
    "\n",
    "        id_ = self.paths[index][0].parent.stem\n",
    "\n",
    "        sample['id']  = id_\n",
    "        img_data, header = nrrd.read(self.paths[index][0])\n",
    "        img_data = np.int16(img_data)\n",
    "        img_data = rearrange(img_data, 'h w d -> d w h')\n",
    "        # img_data = sitk.GetArrayFromImage(img)\n",
    "        img_data = np.expand_dims(img_data, axis=3)\n",
    "        sample['input'] = img_data\n",
    "\n",
    "        mask_data, header = nrrd.read(self.paths[index][-1])\n",
    "        mask_data = np.int16(mask_data)\n",
    "        # print(mask_data.dtype)\n",
    "        mask_data = rearrange(mask_data, 'h w d -> d w h')\n",
    "        # mask_data = sitk.GetArrayFromImage(mask)\n",
    "        mask_data = np.expand_dims(mask_data, axis=3)\n",
    "\n",
    "        sample['target'] = mask_data\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        \n",
    "        return sample\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def read_nrrd_file(path):\n",
    "        img = sitk.ReadImage(str(path), sitk.sitkFloat32)\n",
    "\n",
    "        return img\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_nrrd(full_path_filename,dtype=sitk.sitkFloat32):\n",
    "        '''\n",
    "        N*h*W\n",
    "        :param full_path_filename:\n",
    "        :return:*H*W\n",
    "        '''\n",
    "        if not os.path.exists(full_path_filename):\n",
    "            raise FileNotFoundError\n",
    "        image = sitk.ReadImage(full_path_filename)\n",
    "        image = sitk.Cast(sitk.RescaleIntensity(image), dtype)\n",
    "        # data = sitk.GetArrayFromImage(image) # N*H*W\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load image Python extension: dlopen(/opt/anaconda3/envs/sega/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <CAE66874-17C2-35C9-9C4D-6BA9770AF17F> /opt/anaconda3/envs/sega/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <DAEF2BE1-BBB4-3005-8003-63A504CDB9D9> /opt/anaconda3/envs/sega/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nrrd\n",
    "from einops import  rearrange\n",
    "from monai.networks.nets import UNETR, SwinUNETR, SegResNet\n",
    "\n",
    "# from src.models.components.models import BaselineUNet, FastSmoothSENormDeepUNet_supervision_skip_no_drop\n",
    "# from src.models.sega_module import SegaModule\n",
    "# from src.data.components.sega_dataset import SegaDataset\n",
    "# from src.models.components.metrics import dice\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, random_split, Subset\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(input, target):\n",
    "    axes = tuple(range(1, input.dim()))\n",
    "    bin_input = (input > 0.5).float()\n",
    "\n",
    "    intersect = (bin_input * target).sum(dim=axes)\n",
    "    union = bin_input.sum(dim=axes) + target.sum(dim=axes)\n",
    "    score = 2 * intersect / (union + 1e-5)\n",
    "\n",
    "    return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = pathlib.Path('/Users/ikboljon.sobirov/Documents/sega23/segaorta_resampled/')\n",
    "\n",
    "chkpt_paths = ['/Users/ikboljon.sobirov/Documents/sega23/epoch_047.ckpt',\n",
    "                '/Users/ikboljon.sobirov/Documents/sega23/epoch_062.ckpt',\n",
    "                # '/Users/ikboljon.sobirov/Documents/sega23/epoch_097.ckpt',\n",
    "                ]\n",
    "\n",
    "output_path = pathlib.Path('/Users/ikboljon.sobirov/Documents/sega23/segaorta_resampled_pred/')\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 12 12\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from augmentations import *\n",
    "\n",
    "trans_pred = Compose([\n",
    "                    NormalizeIntensity(),\n",
    "                    ToTensor(), \n",
    "                    Resizing(z=256,x=256,y=256),\n",
    "                    ])\n",
    "\n",
    "trans_orig = Compose([\n",
    "                    NormalizeIntensity(),\n",
    "                    ToTensor(), \n",
    "                    ]) \n",
    "\n",
    "dataset_pred = SegaDataset(data_path, transforms=trans_pred)\n",
    "dataset_orig = SegaDataset(data_path, transforms=trans_orig)\n",
    "\n",
    "\n",
    "full_indices = range(len(dataset_pred))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=786)\n",
    "\n",
    "train_idx = {}\n",
    "test_idx = {}\n",
    "\n",
    "key = 1\n",
    "for i,j in kf.split(full_indices):\n",
    "    train_idx[key] = i\n",
    "    test_idx[key] = j\n",
    "\n",
    "    key += 1\n",
    "\n",
    "_, val_dataset_pred = Subset(dataset_pred, train_idx[1]), Subset(dataset_pred, test_idx[1])\n",
    "_, val_dataset_orig = Subset(dataset_orig, train_idx[1]), Subset(dataset_orig, test_idx[1])\n",
    "\n",
    "print(len(dataset_pred), len(val_dataset_orig), len(val_dataset_pred))\n",
    "\n",
    "\n",
    "\n",
    "pred_loader = DataLoader(\n",
    "            dataset=val_dataset_pred,\n",
    "            batch_size=1,\n",
    "            # num_workers=8,\n",
    "            pin_memory=True,\n",
    "            shuffle=False,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "orig_loader = DataLoader(\n",
    "            dataset=val_dataset_orig,\n",
    "            batch_size=1,\n",
    "            # num_workers=8,\n",
    "            pin_memory=True,\n",
    "            shuffle=False,\n",
    "            drop_last=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = next(iter(pred_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_orig = next(iter(orig_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D9']\n",
      "['D9']\n"
     ]
    }
   ],
   "source": [
    "print(data_pred['id'])\n",
    "print(data_orig['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_weights(model, path_to_model_weights):\n",
    "    model_state_dict = torch.load(path_to_model_weights, map_location=lambda storage, loc: storage)\n",
    "    state_dict = model_state_dict['state_dict']\n",
    "    \n",
    "    for key in list(state_dict):\n",
    "        state_dict[key.replace(\"model.\", \"\")] = state_dict.pop(key)\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run inference for an ensemble of 2 models on CPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SegResNet(\n",
       "  (act_mod): ReLU(inplace=True)\n",
       "  (convInit): Convolution(\n",
       "    (conv): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  )\n",
       "  (down_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Identity()\n",
       "      (1): ResBlock(\n",
       "        (norm1): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (norm1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (norm1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ResBlock(\n",
       "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (4): ResBlock(\n",
       "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (norm1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (norm1): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_samples): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): UpSample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0, 2.0), mode='trilinear')\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): UpSample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0, 2.0), mode='trilinear')\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(16, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): UpSample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0, 2.0), mode='trilinear')\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_final): Sequential(\n",
       "    (0): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Convolution(\n",
       "      (conv): Conv3d(8, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SegResNet(in_channels=1, out_channels=1)\n",
    "\n",
    "# if device.type == 'cpu':\n",
    "#     checkpoint = torch.load(chkpt_path, map_location=torch.device('cpu'))\n",
    "# else:\n",
    "#     checkpoint = torch.load(chkpt_path)\n",
    "\n",
    "if device.type == 'cpu':\n",
    "    print(f'Run inference for an ensemble of {len(chkpt_paths)} models on CPU')\n",
    "else:\n",
    "    print(f'Run inference for an ensemble of {len(chkpt_paths)} models'\n",
    "            f' on {torch.cuda.get_device_name(torch.cuda.current_device())}')\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dictionary = {}\n",
    "metric_dictionary['id'] = []\n",
    "metric_dictionary['resize_metric'] = []\n",
    "metric_dictionary['orig_metric'] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ['D9']\n",
      "id: D9, metric_rs: 0.9270153045654297, metric_org: 0.9248929619789124\n",
      "Processing: ['K5']\n",
      "id: K5, metric_rs: 0.8301315307617188, metric_org: 0.8283371925354004\n",
      "Processing: ['R7']\n",
      "id: R7, metric_rs: 0.8323187828063965, metric_org: 0.8276515603065491\n",
      "Processing: ['R6']\n",
      "id: R6, metric_rs: 0.8188565969467163, metric_org: 0.817129373550415\n",
      "Processing: ['K7']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for sample, orig in zip(pred_loader, orig_loader):\n",
    "        print(\"Processing:\", sample['id'])\n",
    "\n",
    "        input = sample['input']\n",
    "\n",
    "        ensemble_output = 0\n",
    "        for path in chkpt_paths:\n",
    "            model = load_model_weights(model, path)\n",
    "            output = model(input)\n",
    "            output = output.cpu()\n",
    "\n",
    "            ensemble_output += output\n",
    "\n",
    "        ensemble_output /= len(chkpt_paths)\n",
    "\n",
    "        # output = model(input)\n",
    "\n",
    "        # y_pred = output.float()\n",
    "        y_pred = torch.where(ensemble_output>0.5, 1, 0).float()\n",
    "        # Upsample back to original size\n",
    "        y_pred = y_pred.squeeze(0)\n",
    "        y_orig = tio.Resize(orig['input'].squeeze().shape, image_interpolation='nearest')(y_pred)\n",
    "        # Save prediction:\n",
    "\n",
    "        \n",
    "        metric_value_rs = dice(y_pred.unsqueeze(0).detach(), sample['target'].detach())\n",
    "        metric_value_or = dice(y_orig.unsqueeze(0).detach(), orig['target'].detach())\n",
    "\n",
    "        metric_dictionary['id'].append(sample['id'][0])\n",
    "        metric_dictionary['resize_metric'].append(metric_value_rs.item())\n",
    "        metric_dictionary['orig_metric'].append(metric_value_or.item())\n",
    "        \n",
    "        print(f\"id: {sample['id'][0]}, metric_rs: {metric_value_rs}, metric_org: {metric_value_or}\")\n",
    "\n",
    "        if not os.path.exists(output_path / sample['id'][0]):\n",
    "            os.makedirs(output_path / sample['id'][0], exist_ok=True)\n",
    "\n",
    "        # write_nifti(sitk.GetImageFromArray(y_pred.squeeze()),  str(output_path / sample['id'][0] / (sample['id'][0] +'_resize.nrrd')))\n",
    "        # write_nifti(sitk.GetImageFromArray(y_orig.squeeze()),  str(output_path / sample['id'][0] / (sample['id'][0] +'.nrrd')))\n",
    "        sitk.WriteImage(sitk.GetImageFromArray(y_orig.squeeze()),  str(output_path / sample['id'][0] / (sample['id'][0] +'_pr.seg.nrrd')), useCompression=True)\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resize: 0.8293382028738657\n",
      "Original Mean: 0.8323791027069092\n",
      "Original SD: 0.04566924787160509\n"
     ]
    }
   ],
   "source": [
    "print(\"Resize:\", np.mean(sorted(metric_dictionary['resize_metric'])))\n",
    "print(\"Original Mean:\", np.mean(sorted(metric_dictionary['orig_metric'])[1:]))\n",
    "print(\"Original SD:\", np.std(sorted(metric_dictionary['orig_metric'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7565342783927917,\n",
       " 0.7642958760261536,\n",
       " 0.788438081741333,\n",
       " 0.8144479990005493,\n",
       " 0.8147838115692139,\n",
       " 0.8229645490646362,\n",
       " 0.8254221081733704,\n",
       " 0.8269250392913818,\n",
       " 0.8315982222557068,\n",
       " 0.8474909663200378,\n",
       " 0.9014589786529541,\n",
       " 0.9183444976806641]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sorted(metric_dictionary['orig_metric']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.DataFrame.from_dict(metric_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>resize_metric</th>\n",
       "      <th>orig_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D9</td>\n",
       "      <td>0.918307</td>\n",
       "      <td>0.918344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K5</td>\n",
       "      <td>0.791912</td>\n",
       "      <td>0.788438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R7</td>\n",
       "      <td>0.819081</td>\n",
       "      <td>0.814784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R6</td>\n",
       "      <td>0.765825</td>\n",
       "      <td>0.764296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K7</td>\n",
       "      <td>0.819451</td>\n",
       "      <td>0.814448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D4</td>\n",
       "      <td>0.911339</td>\n",
       "      <td>0.901459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R10</td>\n",
       "      <td>0.823756</td>\n",
       "      <td>0.822965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K1</td>\n",
       "      <td>0.849784</td>\n",
       "      <td>0.847491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>K6</td>\n",
       "      <td>0.834172</td>\n",
       "      <td>0.831598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R18</td>\n",
       "      <td>0.757631</td>\n",
       "      <td>0.756534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>R11</td>\n",
       "      <td>0.832721</td>\n",
       "      <td>0.826925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>R3</td>\n",
       "      <td>0.828080</td>\n",
       "      <td>0.825422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  resize_metric  orig_metric\n",
       "0    D9       0.918307     0.918344\n",
       "1    K5       0.791912     0.788438\n",
       "2    R7       0.819081     0.814784\n",
       "3    R6       0.765825     0.764296\n",
       "4    K7       0.819451     0.814448\n",
       "5    D4       0.911339     0.901459\n",
       "6   R10       0.823756     0.822965\n",
       "7    K1       0.849784     0.847491\n",
       "8    K6       0.834172     0.831598\n",
       "9   R18       0.757631     0.756534\n",
       "10  R11       0.832721     0.826925\n",
       "11   R3       0.828080     0.825422"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.to_csv('metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample back to the original size/spacing/etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path = '/Users/ikboljon.sobirov/Documents/sega23/SegAorta/'\n",
    "predicted_path = '/Users/ikboljon.sobirov/Documents/sega23/segaorta_resampled_pred/'\n",
    "out_path = '/Users/ikboljon.sobirov/Documents/sega23/segaorta_resampled_pred_resampled/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients = os.listdir(predicted_path)\n",
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_sitk_image_new(reference_image,\n",
    "                        original_img,\n",
    "                        interpolator = sitk.sitkNearestNeighbor):\n",
    "    \n",
    "\n",
    "    fill_value = 0\n",
    "\n",
    "    orig_pixelid = original_img.GetPixelIDValue()\n",
    "    orig_origin = reference_image.GetOrigin()\n",
    "    orig_direction = original_img.GetDirection()\n",
    "    orig_spacing = np.array(original_img.GetSpacing())\n",
    "    orig_size = original_img.GetSize()\n",
    "\n",
    "    # new_size = original_img.GetSize() * (orig_spacing / orig_spacing)\n",
    "    # new_size = np.ceil(new_size).astype(int)  # Image dimensions are in integers\n",
    "    # new_size = [int(s) for s in new_size]\n",
    "    \n",
    "    resample_filter = sitk.ResampleImageFilter()\n",
    "    resample_filter.SetSize(orig_size)\n",
    "    resample_filter.SetTransform(sitk.Transform())\n",
    "    resample_filter.SetInterpolator(interpolator)\n",
    "    # resample_filter.SetOrigin(orig_origin)\n",
    "    resample_filter.SetOutputSpacing(orig_spacing)\n",
    "    resample_filter.SetOutputDirection(orig_direction)\n",
    "    resample_filter.SetDefaultPixelValue(fill_value)\n",
    "    resample_filter.SetOutputPixelType(orig_pixelid)\n",
    "\n",
    "    resampled_sitk_image = resample_filter.Execute(reference_image)\n",
    "    resampled_sitk_image.SetOrigin(original_img.GetOrigin())\n",
    "    return resampled_sitk_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before resampling:\n",
      "Predicted: (294, 383, 445) (1.0, 1.0, 1.0) (0.0, 0.0, 0.0) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Original (512, 666, 149) (0.57421875, 0.57421875, 2.9864851351351356) (-149.058, -20.514843750000004, -851.4998999999999) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "After resampling:\n",
      "Resampled: (512, 666, 149) (0.57421875, 0.57421875, 2.9864851351351356) (-149.058, -20.514843750000004, -851.4998999999999) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Before resampling:\n",
      "Predicted: (448, 448, 755) (1.0, 1.0, 1.0) (0.0, 0.0, 0.0) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Original (512, 512, 302) (0.875, 0.875, 2.5) (-230.5625, -385.5625, -669.2) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "After resampling:\n",
      "Resampled: (512, 512, 302) (0.875, 0.875, 2.5) (-230.5625, -385.5625, -669.2) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Before resampling:\n",
      "Predicted: (480, 480, 713) (1.0, 1.0, 1.0) (0.0, 0.0, 0.0) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Original (512, 512, 1140) (0.9375, 0.9375, 0.625) (-257.20001200000013, -240.0, -735.6249999999995) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "After resampling:\n",
      "Resampled: (512, 512, 1140) (0.9375, 0.9375, 0.625) (-257.20001200000013, -240.0, -735.6249999999995) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Before resampling:\n",
      "Predicted: (371, 371, 665) (1.0, 1.0, 1.0) (0.0, 0.0, 0.0) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Original (512, 512, 1064) (0.7246089999999996, 0.7246089999999996, 0.6249999999999999) (-185.4999999999999, -185.49999999999991, -655.3749999999997) (0.9999999999999999, 0.0, 0.0, 0.0, 0.9999999999999999, 0.0, 0.0, 0.0, 1.0)\n",
      "After resampling:\n",
      "Resampled: (512, 512, 1064) (0.7246089999999996, 0.7246089999999996, 0.6249999999999999) (-185.4999999999999, -185.49999999999991, -655.3749999999997) (0.9999999999999999, 0.0, 0.0, 0.0, 0.9999999999999999, 0.0, 0.0, 0.0, 1.0)\n",
      "Before resampling:\n",
      "Predicted: (360, 360, 655) (1.0, 1.0, 1.0) (0.0, 0.0, 0.0) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Original (512, 512, 262) (0.7031249999999999, 0.7031249999999999, 2.5000000000000004) (-179.99999999999997, -176.99999999999994, -650.5) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "After resampling:\n",
      "Resampled: (512, 512, 262) (0.7031249999999999, 0.7031249999999999, 2.5000000000000004) (-179.99999999999997, -176.99999999999994, -650.5) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Before resampling:\n",
      "Predicted: (386, 501, 538) (1.0, 1.0, 1.0) (0.0, 0.0, 0.0) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Original (512, 666, 180) (0.7519531250000001, 0.7519531250000001, 2.9888256983240225) (-190.575, -79.80039000000001, -906.4098999999999) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "After resampling:\n",
      "Resampled: (512, 666, 180) (0.7519531250000001, 0.7519531250000001, 2.9888256983240225) (-190.575, -79.80039000000001, -906.4098999999999) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Before resampling:\n",
      "Predicted: (360, 360, 656) (1.0, 1.0, 1.0) (0.0, 0.0, 0.0) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Original (512, 512, 1049) (0.7031249999999999, 0.7031249999999999, 0.6250000000000001) (-174.0, -181.00000000000009, -640.0000000000001) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "After resampling:\n",
      "Resampled: (512, 512, 1049) (0.7031249999999999, 0.7031249999999999, 0.6250000000000001) (-174.0, -181.00000000000009, -640.0000000000001) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Before resampling:\n",
      "Predicted: (415, 415, 530) (1.0, 1.0, 1.0) (0.0, 0.0, 0.0) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Original (512, 512, 1059) (0.8105468749999998, 0.8105468749999998, 0.5) (-210.0947265624998, -377.59472656249994, -1151.6) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "After resampling:\n",
      "Resampled: (512, 512, 1059) (0.8105468749999998, 0.8105468749999998, 0.5) (-210.0947265624998, -377.59472656249994, -1151.6) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Before resampling:\n",
      "Predicted: (375, 375, 673) (1.0, 1.0, 1.0) (0.0, 0.0, 0.0) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Original (512, 512, 269) (0.732421875, 0.732421875, 2.4999999999999996) (-198.1337890625, -344.1337890624998, -726.3999999999996) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "After resampling:\n",
      "Resampled: (512, 512, 269) (0.732421875, 0.732421875, 2.4999999999999996) (-198.1337890625, -344.1337890624998, -726.3999999999996) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Before resampling:\n",
      "Predicted: (529, 529, 738) (1.0, 1.0, 1.0) (0.0, 0.0, 0.0) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Original (512, 512, 295) (1.0332030000000003, 1.0332030000000003, 2.5000000000000013) (-264.50000000000006, -264.5, -717.5000000000002) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "After resampling:\n",
      "Resampled: (512, 512, 295) (1.0332030000000003, 1.0332030000000003, 2.5000000000000013) (-264.50000000000006, -264.5, -717.5000000000002) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Before resampling:\n",
      "Predicted: (430, 430, 672) (1.0, 1.0, 1.0) (0.0, 0.0, 0.0) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Original (512, 512, 672) (0.837891, 0.837891, 1.0) (-212.300003, -193.5, -677.98999) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "After resampling:\n",
      "Resampled: (512, 512, 672) (0.837891, 0.837891, 1.0) (-212.300003, -193.5, -677.98999) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Before resampling:\n",
      "Predicted: (459, 459, 713) (1.0, 1.0, 1.0) (0.0, 0.0, 0.0) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Original (512, 512, 1140) (0.896484, 0.896484, 0.625) (-235.5, -237.0, -681.125) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "After resampling:\n",
      "Resampled: (512, 512, 1140) (0.896484, 0.896484, 0.625) (-235.5, -237.0, -681.125) (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "for p in patients:\n",
    "    p_path_pred = os.path.join(predicted_path, p, (p+'_pr.seg.nrrd'))\n",
    "    p_path_orig = os.path.join(original_path, p, (p+'.seg.nrrd'))\n",
    "\n",
    "    p_pred = sitk.ReadImage(p_path_pred)\n",
    "    p_orig = sitk.ReadImage(p_path_orig)\n",
    "\n",
    "    print(\"Before resampling:\")\n",
    "    print(\"Predicted:\", p_pred.GetSize(), p_pred.GetSpacing(), p_pred.GetOrigin(), p_pred.GetDirection())\n",
    "    print(\"Original\", p_orig.GetSize(), p_orig.GetSpacing(), p_orig.GetOrigin(), p_orig.GetDirection())\n",
    "\n",
    "    # p_pred_resampled = sitk.Resample(p_pred, p_orig, sitk.Transform(), sitk.sitkNearestNeighbor, 1, p_pred.GetPixelID())\n",
    "    attributes = get_attributes(p_orig)\n",
    "    p_pred_resampled = resample_sitk_image_new(p_pred, \n",
    "                                                p_orig,\n",
    "                                                interpolator = sitk.sitkNearestNeighbor)\n",
    "    \n",
    "    # p_pred_resampled_fake = sitk.GetArrayFromImage(p_pred_resampled)\n",
    "    # p_pred_resampled = sitk.GetImageFromArray(p_pred_resampled_fake)\n",
    "    print(\"After resampling:\")\n",
    "    print(\"Resampled:\", p_pred_resampled.GetSize(), p_pred_resampled.GetSpacing(), p_pred_resampled.GetOrigin(), p_pred_resampled.GetDirection())\n",
    "\n",
    "    if not os.path.exists(os.path.join(out_path, p)):\n",
    "        os.makedirs(os.path.join(out_path, p), exist_ok=True)\n",
    "\n",
    "    sitk.WriteImage(p_pred_resampled, os.path.join(out_path, p, (p +'_pr.seg.nrrd')), useCompression=True)\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(sitk.GetArrayFromImage(p_pred_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b1f8b700>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAGiCAYAAACmkA4CAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmkklEQVR4nO3de3BUZZ7/8U+HJE0idBoI6QYliCvKMlwWg8ZWp5wqsiCTnVWkZimKraUcayww7nphrDWzJY67tRNKyxkv66Jz8bI7U7KytXhBZMwkGkaJASIZuRlxBEMpncyQSXfAkFt/f3/444wt6JDLk06H96vqW0XO85xzvk8RPh67n3R8ZmYCADiTkeoGAGCkI2gBwDGCFgAcI2gBwDGCFgAcI2gBwDGCFgAcI2gBwDGCFgAcI2gBwLGUBu3jjz+uCy+8UKNHj1ZxcbF27NiRynYAwImUBe3//M//6K677tJ9992nd955R3PnztWiRYvU0tKSqpYAwAlfqj5Upri4WJdffrn+4z/+Q5KUSCQ0ZcoU/eM//qPuueeeVLQEAE5kpuKmXV1dqq+vV3l5uXcsIyNDJSUlqq2tPW1+Z2enOjs7va8TiYRaW1s1YcIE+Xy+IekZwLnJzNTe3q7JkycrI6N/LwKkJGj/8Ic/qLe3V6FQKOl4KBTSe++9d9r8iooK3X///UPVHgCc5siRI7rgggv6dW5a7DooLy9XLBbzqqmpKdUtATjHjB07tt/npuSJNj8/X6NGjVJzc3PS8ebmZoXD4dPm+/1++f3+oWoPAE4zkJcpU/JEm52draKiIlVVVXnHEomEqqqqFIlEUtESADiTkidaSbrrrru0cuVKzZ8/X1dccYUefvhhnThxQjfddFOqWgIAJ1IWtMuWLdPvf/97rV27VtFoVH/1V3+lrVu3nvYGGQCku5Ttox2IeDyuvLy8VLcB4BwSi8UUCAT6dW5a7DoAgHRG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAYwQtADhG0AKAY30O2m3btulb3/qWJk+eLJ/PpxdeeCFp3My0du1aTZo0STk5OSopKdHBgweT5rS2tmrFihUKBAIKBoO6+eabdfz48QEtBACGqz4H7YkTJzR37lw9/vjjZxx/4IEH9Oijj+qJJ55QXV2dzjvvPC1atEgnT5705qxYsUL79u1TZWWlNm/erG3btumWW27p/yoAYDizAZBkmzZt8r5OJBIWDoftwQcf9I61tbWZ3++35557zszM9u/fb5Js586d3pxXX33VfD6fffzxx2d131gsZpIoiqKGrGKxWL+zclBfoz106JCi0ahKSkq8Y3l5eSouLlZtba0kqba2VsFgUPPnz/fmlJSUKCMjQ3V1dWe8bmdnp+LxeFIBQLoY1KCNRqOSpFAolHQ8FAp5Y9FoVAUFBUnjmZmZGj9+vDfniyoqKpSXl+fVlClTBrNtAHAqLXYdlJeXKxaLeXXkyJFUtwQAZ21QgzYcDkuSmpubk443Nzd7Y+FwWC0tLUnjPT09am1t9eZ8kd/vVyAQSCoASBeDGrTTpk1TOBxWVVWVdywej6uurk6RSESSFIlE1NbWpvr6em9OdXW1EomEiouLB7MdABge+vruWXt7u+3evdt2795tkuxHP/qR7d692z766CMzM1u3bp0Fg0F78cUX7d1337Xrr7/epk2bZh0dHd41rrvuOps3b57V1dXZm2++adOnT7fly5efdQ/sOqAoaqhrILsO+hy0r7/++hmbWLlypZl9tsXr3nvvtVAoZH6/3xYsWGCNjY1J1zh27JgtX77cxowZY4FAwG666SZrb28/6x4IWoqihroGErQ+MzOlmXg8rry8vFS3AeAcEovF+v3+UFrsOgCAdEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AOEbQAoBjBC0AONanoK2oqNDll1+usWPHqqCgQDfccIMaGxuT5pw8eVJlZWWaMGGCxowZo6VLl6q5uTlpTlNTk0pLS5Wbm6uCggLdfffd6unpGfhqAGAY6lPQ1tTUqKysTG+//bYqKyvV3d2thQsX6sSJE96cO++8Uy+//LI2btyompoaffLJJ7rxxhu98d7eXpWWlqqrq0vbt2/Xs88+q2eeeUZr164dvFUBwHBiA9DS0mKSrKamxszM2traLCsryzZu3OjNOXDggEmy2tpaMzPbsmWLZWRkWDQa9easX7/eAoGAdXZ2ntV9Y7GYSaIoihqyisVi/c7KAb1GG4vFJEnjx4+XJNXX16u7u1slJSXenBkzZqiwsFC1tbWSpNraWs2ePVuhUMibs2jRIsXjce3bt++M9+ns7FQ8Hk8qAEgX/Q7aRCKhO+64Q1dffbVmzZolSYpGo8rOzlYwGEyaGwqFFI1GvTmfD9lT46fGzqSiokJ5eXleTZkypb9tA8CQ63fQlpWVae/evdqwYcNg9nNG5eXlisViXh05csT5PQFgsGT256TbbrtNmzdv1rZt23TBBRd4x8PhsLq6utTW1pb0VNvc3KxwOOzN2bFjR9L1Tu1KODXni/x+v/x+f39aBYCU69MTrZnptttu06ZNm1RdXa1p06YljRcVFSkrK0tVVVXescbGRjU1NSkSiUiSIpGI9uzZo5aWFm9OZWWlAoGAZs6cOZC1AMDw1Jd3zlavXm15eXn2xhtv2NGjR7369NNPvTmrVq2ywsJCq66utl27dlkkErFIJOKN9/T02KxZs2zhwoXW0NBgW7dutYkTJ1p5eflZ98GuA4qihroGsuugT0H7ZQ08/fTT3pyOjg679dZbbdy4cZabm2tLliyxo0ePJl3n8OHDtnjxYsvJybH8/Hxbs2aNdXd3n3UfBC1FUUNdAwla3/8P0LQSj8eVl5eX6jYAnENisZgCgUC/zuWzDgDAMYIWABwjaAHAMYIWABwjaAHAMYIWABwjaAHAMYIWABwjaAHAMYIWABwjaAHAMYIWABwjaAHAMYIWABwjaAHAMYIWABzr1y9nBEaazMwz/1MwM/X29g5xNxhpCFqc8/x+v15//XWFQqHTxt5++22tWLEiBV1hJCFocc768Y9/rOLiYmVkZGjevHnKzs4+bU5+fr62b9+utrY2LV26VB0dHSnoFOmOoMU5xefzaerUqcrMzFRRUZEikchXzg8EAopEIvrjH/+oSy65RCdOnFBHR4c+/vjjIeoYIwG/nBHnjPPOO095eXnauXOnQqGQMjIy5PP5zvr8U6/Vbt++Xddff713vKurSydOnBj0fjG88MsZgbPwwAMPaP/+/Zo0aZJGjRrVp5CVpFGjRmnUqFG66qqr9OGHH3r12GOPOeoYIwUvHeCckZubOyj/JzRq1CgFg8Gk6wJfhaDFiFVYWKgpU6ZozZo1CofDuvjii53cp6SkRNu3b5ckvfDCC3r++ed1+PBhJ/dCmrI0FIvFTBJFfWX967/+a0q+Px966KGUr50a/IrFYv3+nuA1WoxI5513nnJyclJy79GjR2v8+PEaNWpUSu6P4YddBxhRfD6fRo0apccff1wrV66U3+8f8h46OzvV0dGhv/7rv9auXbuG/P5wYyC7DniNFiPKtddeq5///OcqKChISchKn/2kmd/v/9If68W5h5cOMKLk5OTooosu0pgxY1LdiubMmaPx48enug0MAwQtRoxAIKDzzz8/1W14nnzySV177bWpbgPDAEGLEePv/u7v9OSTT6a6DeA0BC1GjIyMDGVk8C2N4YfvSsChq666ytkPSiB9ELSAQ9/73vdUWlqa6jaQYgQtADhG0AIOPfXUU6qpqUl1G0gxghZwaPPmzWpoaEh1G0gxfnQFI8aHH36oN998U9dcc01K+zh48KB++9vfSpI++eSTlPaC4YGgxYjx61//WllZWdqyZUvKevjxj3+sRx55RB999FHKesDww0sHwCA6dOgQIYvTELQYUfbv36/3338/Jff++c9/rm3btqXk3hjeCFqMKB999JEefvhhHThwYEjv+8knn+jhhx/2XpsFPo+gxYizfv167dy5c0jv+eGHH2rv3r1Dek+kDz74GyPSxRdfrPz8fGVkZOi///u/ddFFFzm5zy9+8Qs9/vjjam9v1759+5zcA8PDQD74u0+/M+w///M/bfbs2TZ27FgbO3asXXnllbZlyxZvvKOjw2699VYbP368nXfeeXbjjTdaNBpNusZHH31k3/zmNy0nJ8cmTpxo3/ve96y7u7tPv3+H3xlG9aUWLFhgS5Ysserq6j59n53Jb37zG1uyZIlXs2bNSvn6qKGpgfzOsD4F7UsvvWSvvPKKvf/++9bY2Gjf//73LSsry/bu3WtmZqtWrbIpU6ZYVVWV7dq1y6688kq76qqrvPN7enps1qxZVlJSYrt377YtW7ZYfn6+lZeX96lpgpbqTz322GPW2tpqra2tduzYMevq6jrr77lEImGtra3205/+NOXroFJTQxa0ZzJu3Dj72c9+Zm1tbZaVlWUbN270xg4cOGCSrLa21szMtmzZYhkZGUlPuevXr7dAIGCdnZ1nfU+ClupP5ebmWjAY9OpXv/qVdXd3n1VFo1E7//zzLTc3N+XroFJTAwnafv/AQm9vrzZu3KgTJ04oEomovr5e3d3dKikp8ebMmDFDhYWFqq2t1ZVXXqna2lrNnj1boVDIm7No0SKtXr1a+/bt07x58854r87OTnV2dnpfx+Px/raNc9inn36qTz/91Pt65cqVys3NPatze3t79cknn8jS7y0NDAN9Dto9e/YoEono5MmTGjNmjDZt2qSZM2eqoaFB2dnZCgaDSfNDoZCi0agkKRqNJoXsqfFTY1+moqJC999/f19bBb7SV33PAYOpz9u7Lr30UjU0NKiurk6rV6/WypUrtX//fhe9ecrLyxWLxbw6cuSI0/sBwGDq8xNtdna294nxRUVF2rlzpx555BEtW7ZMXV1damtrS3qqbW5uVjgcliSFw2Ht2LEj6XrNzc3e2Jc59eubASAdDfgHFhKJhDo7O1VUVKSsrCxVVVV5Y42NjWpqalIkEpEkRSIR7dmzRy0tLd6cyspKBQIBzZw5c6CtAMDw1Jd3zu655x6rqamxQ4cO2bvvvmv33HOP+Xw+e+2118zss+1dhYWFVl1dbbt27bJIJGKRSMQ7/9T2roULF1pDQ4Nt3brVJk6cyPYuiqKGfQ3Z9q7vfOc7NnXqVMvOzraJEyfaggULvJA1+9MPLIwbN85yc3NtyZIldvTo0aRrHD582BYvXmw5OTmWn59va9as4QcWKIoa9jWQoOVHcAHgLAzkR3D5UBkAcIygBQDHCFoAcIygBQDHCFoAcIygBQDHCFoAcIygBQDHCFoAcIygBQDHCFoAcIygBQDHCFoAcIygBQDHCFoAcIygBQDHCFoAcIygBQDHCFoAcIygBQDHCFoAcIygBQDHCFoAcIygBQDHCFoAcIygBQDHCFoAcIygBQDHCFoAcIygBQDHCFoAcIygBQDHCFoAcIygBQDHCFoAcCwz1Q0A6WL06NHKyck57bjP55OZ6fjx4+ru7k5BZxjuCFrgzxg3bpxWrlypa665RgsWLPjSec8//7zee+891dfXa9u2bUPYIYY9S0OxWMwkUdSQ1IwZM6y3t/esvz8feuihlPdMDX7FYrF+ZxZPtMBXCAQCmjdvnnw+31mfc/755+uqq66SJL333ntqbW111R7SRb8jOoV4oqVcV2Zmpv3kJz+xbdu2Deh79e2337a/+Zu/Sfl6qIEXT7TAIBs1apQWL16sCy64YEDXKS4u1l/8xV8MUldIV2zvAr4gJydHq1ev1tixYwflet/4xjd07bXXDsq1kJ54ogU+JxAI6Nvf/rbWrVsnv98/KNe84YYblJmZqV27dunEiRODck2kF5+ZWaqb6Kt4PK68vLxUt4ERaObMmdq7d2+f3vw6G729vZoxY4Y++OCDQb0uhk4sFlMgEOjXubx0AACODSho161bJ5/PpzvuuMM7dvLkSZWVlWnChAkaM2aMli5dqubm5qTzmpqaVFpaqtzcXBUUFOjuu+9WT0/PQFoBgGGr30G7c+dOPfnkk5ozZ07S8TvvvFMvv/yyNm7cqJqaGn3yySe68cYbvfHe3l6Vlpaqq6tL27dv17PPPqtnnnlGa9eu7f8qgDSQmZk56C9JIE30Z09Ye3u7TZ8+3SorK+3aa6+122+/3czM2traLCsryzZu3OjNPXDggEmy2tpaMzPbsmWLZWRkWDQa9easX7/eAoGAdXZ2ntX92UdLuaqZM2daIpHozz+LP6upqcmKiopSvkaqfzWQfbT9eqItKytTaWmpSkpKko7X19eru7s76fiMGTNUWFio2tpaSVJtba1mz56tUCjkzVm0aJHi8bj27dt3xvt1dnYqHo8nFeDCoUOHVFpaqpMnTw76tadMmaLRo0cP+nUx/PV5e9eGDRv0zjvvaOfOnaeNRaNRZWdnKxgMJh0PhUKKRqPenM+H7KnxU2NnUlFRofvvv7+vrQJ91tHRofr6et4zwKDq0xPtkSNHdPvtt+uXv/zlkP6Xuby8XLFYzKsjR44M2b1x7kkkEmpra5MN4s7HRCKhf/u3f9OHH344aNdE+uhT0NbX16ulpUWXXXaZMjMzlZmZqZqaGj366KPKzMxUKBRSV1eX2traks5rbm5WOByWJIXD4dN2IZz6+tScL/L7/QoEAkkFuHLs2DEVFRXp6NGjg3ZNM9N//dd/Deo1kT76FLQLFizQnj171NDQ4NX8+fO1YsUK789ZWVmqqqryzmlsbFRTU5MikYgkKRKJaM+ePWppafHmVFZWKhAIaObMmYO0LKD/zEyxWEyJRCLVrWCkGOg7qZ/fdWBmtmrVKissLLTq6mrbtWuXRSIRi0Qi3nhPT4/NmjXLFi5caA0NDbZ161abOHGilZeXn/U92XVAuS6fz2eXXXaZlZWVDfSfiJmZbdiwwUaPHp3ydVH9r4HsOhj0oO3o6LBbb73Vxo0bZ7m5ubZkyRI7evRo0jmHDx+2xYsXW05OjuXn59uaNWusu7v7rO9J0FJDVfn5+bZkyRJbuXKldXR09OvfyFNPPWVz5sxJ+VqogdVAgpbPOgDOwoQJE3TgwAFNnDixT+cdP35cd999t5544glHnWGo8FkHgGOtra167LHH1NPTo97e3jPO6e3tVU9PT1KtWrVKTz/99BB3i+GGJ1rgLAWDQY0fP15XXHGFnnvuudPGV69erddeey3pWHNzMx+NOEIM5ImWz6MFzlJbW5va2toUCAS0ffv208b379/PPlmcEU+0AHAWeI0WAIYxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHOtT0P7gBz+Qz+dLqhkzZnjjJ0+eVFlZmSZMmKAxY8Zo6dKlam5uTrpGU1OTSktLlZubq4KCAt19993q6ekZnNUAwDCU2dcTvva1r+nXv/71ny6Q+adL3HnnnXrllVe0ceNG5eXl6bbbbtONN96ot956S5LU29ur0tJShcNhbd++XUePHtU//MM/KCsrSz/84Q8HYTkAMAxZH9x33302d+7cM461tbVZVlaWbdy40Tt24MABk2S1tbVmZrZlyxbLyMiwaDTqzVm/fr0FAgHr7Ow86z5isZhJoiiKGrKKxWJ9icskfX6N9uDBg5o8ebIuuugirVixQk1NTZKk+vp6dXd3q6SkxJs7Y8YMFRYWqra2VpJUW1ur2bNnKxQKeXMWLVqkeDyuffv2fek9Ozs7FY/HkwoA0kWfgra4uFjPPPOMtm7dqvXr1+vQoUP6+te/rvb2dkWjUWVnZysYDCadEwqFFI1GJUnRaDQpZE+Nnxr7MhUVFcrLy/NqypQpfWkbAFKqT6/RLl682PvznDlzVFxcrKlTp+r5559XTk7OoDd3Snl5ue666y7v63g8TtgCSBsD2t4VDAZ1ySWX6IMPPlA4HFZXV5fa2tqS5jQ3NyscDkuSwuHwabsQTn19as6Z+P1+BQKBpAKAdDGgoD1+/Lh+97vfadKkSSoqKlJWVpaqqqq88cbGRjU1NSkSiUiSIpGI9uzZo5aWFm9OZWWlAoGAZs6cOZBWAGD46ss7Z2vWrLE33njDDh06ZG+99ZaVlJRYfn6+tbS0mJnZqlWrrLCw0Kqrq23Xrl0WiUQsEol45/f09NisWbNs4cKF1tDQYFu3brWJEydaeXl5n97BY9cBRVFDXQPZddCnoF22bJlNmjTJsrOz7fzzz7dly5bZBx984I13dHTYrbfeauPGjbPc3FxbsmSJHT16NOkahw8ftsWLF1tOTo7l5+fbmjVrrLu7u09NE7QURQ11DSRofWZmSjPxeFx5eXmpbgPAOSQWi/X7/SE+6wAAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHCNoAcAxghYAHOtz0H788cf6+7//e02YMEE5OTmaPXu2du3a5Y2bmdauXatJkyYpJydHJSUlOnjwYNI1WltbtWLFCgUCAQWDQd188806fvz4wFcDAMNQn4L2j3/8o66++mplZWXp1Vdf1f79+/XQQw9p3Lhx3pwHHnhAjz76qJ544gnV1dXpvPPO06JFi3Ty5ElvzooVK7Rv3z5VVlZq8+bN2rZtm2655ZbBWxUADCfWB//8z/9s11xzzZeOJxIJC4fD9uCDD3rH2trazO/323PPPWdmZvv37zdJtnPnTm/Oq6++aj6fzz7++OOz6iMWi5kkiqKoIatYLNaXuEzSpyfal156SfPnz9e3v/1tFRQUaN68efrpT3/qjR86dEjRaFQlJSXesby8PBUXF6u2tlaSVFtbq2AwqPnz53tzSkpKlJGRobq6ujPet7OzU/F4PKkAIF30KWg//PBDrV+/XtOnT9evfvUrrV69Wv/0T/+kZ599VpIUjUYlSaFQKOm8UCjkjUWjURUUFCSNZ2Zmavz48d6cL6qoqFBeXp5XU6ZM6UvbAJBSfQraRCKhyy67TD/84Q81b9483XLLLfrud7+rJ554wlV/kqTy8nLFYjGvjhw54vR+ADCY+hS0kyZN0syZM5OO/eVf/qWampokSeFwWJLU3NycNKe5udkbC4fDamlpSRrv6elRa2urN+eL/H6/AoFAUgFAuuhT0F599dVqbGxMOvb+++9r6tSpkqRp06YpHA6rqqrKG4/H46qrq1MkEpEkRSIRtbW1qb6+3ptTXV2tRCKh4uLifi8EAIatvrxztmPHDsvMzLR///d/t4MHD9ovf/lLy83NtV/84hfenHXr1lkwGLQXX3zR3n33Xbv++utt2rRp1tHR4c257rrrbN68eVZXV2dvvvmmTZ8+3ZYvX37WfbDrgKKooa6B7DroU9Camb388ss2a9Ys8/v9NmPGDPvJT36SNJ5IJOzee++1UChkfr/fFixYYI2NjUlzjh07ZsuXL7cxY8ZYIBCwm266ydrb28+6B4KWoqihroEErc/MTGkmHo8rLy8v1W0AOIfEYrF+vz/EZx0AgGMELQA4RtACgGMELQA4RtACgGMELQA4RtACgGMELQA4RtACgGMELQA4RtACgGMELQA4RtACgGMELQA4RtACgGMELQA4RtACgGMELQA4RtACgGMELQA4RtACgGMELQA4RtACgGMELQA4RtACgGMELQA4RtACgGMELQA4lpZBa2apbgHAOWYguZOWQXvs2LFUtwDgHNPe3t7vczMHsY8hM378eElSU1OT8vLyUtzN4IvH45oyZYqOHDmiQCCQ6nYG1UhemzSy1zeS1yZ9+frMTO3t7Zo8eXK/r52WQZuR8dmDeF5e3oj8Cz8lEAiM2PWN5LVJI3t9I3lt0pnXN9AHurR86QAA0glBCwCOpWXQ+v1+3XffffL7/aluxYmRvL6RvDZpZK9vJK9Ncrs+n7FXCgCcSssnWgBIJwQtADhG0AKAYwQtADhG0AKAY2kZtI8//rguvPBCjR49WsXFxdqxY0eqW/qztm3bpm9961uaPHmyfD6fXnjhhaRxM9PatWs1adIk5eTkqKSkRAcPHkya09raqhUrVigQCCgYDOrmm2/W8ePHh3AVZ1ZRUaHLL79cY8eOVUFBgW644QY1NjYmzTl58qTKyso0YcIEjRkzRkuXLlVzc3PSnKamJpWWlio3N1cFBQW6++671dPTM5RLOaP169drzpw53k8MRSIRvfrqq954Oq/ti9atWyefz6c77rjDO5bO6/vBD34gn8+XVDNmzPDGh2xtlmY2bNhg2dnZ9tRTT9m+ffvsu9/9rgWDQWtubk51a19py5Yt9i//8i/2f//3fybJNm3alDS+bt06y8vLsxdeeMF++9vf2t/+7d/atGnTrKOjw5tz3XXX2dy5c+3tt9+23/zmN3bxxRfb8uXLh3glp1u0aJE9/fTTtnfvXmtoaLBvfvObVlhYaMePH/fmrFq1yqZMmWJVVVW2a9cuu/LKK+2qq67yxnt6emzWrFlWUlJiu3fvti1btlh+fr6Vl5enYklJXnrpJXvllVfs/ffft8bGRvv+979vWVlZtnfvXjNL77V93o4dO+zCCy+0OXPm2O233+4dT+f13Xffffa1r33Njh496tXvf/97b3yo1pZ2QXvFFVdYWVmZ93Vvb69NnjzZKioqUthV33wxaBOJhIXDYXvwwQe9Y21tbeb3++25554zM7P9+/ebJNu5c6c359VXXzWfz2cff/zxkPV+NlpaWkyS1dTUmNlna8nKyrKNGzd6cw4cOGCSrLa21sw++w9RRkaGRaNRb8769estEAhYZ2fn0C7gLIwbN85+9rOfjZi1tbe32/Tp062ystKuvfZaL2jTfX333XefzZ0794xjQ7m2tHrpoKurS/X19SopKfGOZWRkqKSkRLW1tSnsbGAOHTqkaDSatK68vDwVFxd766qtrVUwGNT8+fO9OSUlJcrIyFBdXd2Q9/xVYrGYpD99ylp9fb26u7uT1jdjxgwVFhYmrW/27NkKhULenEWLFikej2vfvn1D2P1X6+3t1YYNG3TixAlFIpERs7aysjKVlpYmrUMaGX93Bw8e1OTJk3XRRRdpxYoVampqkjS0a0urT+/6wx/+oN7e3qRFS1IoFNJ7772Xoq4GLhqNStIZ13VqLBqNqqCgIGk8MzNT48eP9+YMB4lEQnfccYeuvvpqzZo1S9JnvWdnZysYDCbN/eL6zrT+U2OptmfPHkUiEZ08eVJjxozRpk2bNHPmTDU0NKT92jZs2KB33nlHO3fuPG0s3f/uiouL9cwzz+jSSy/V0aNHdf/99+vrX/+69u7dO6RrS6ugxfBXVlamvXv36s0330x1K4Pq0ksvVUNDg2KxmP73f/9XK1euVE1NTarbGrAjR47o9ttvV2VlpUaPHp3qdgbd4sWLvT/PmTNHxcXFmjp1qp5//nnl5OQMWR9p9dJBfn6+Ro0addq7gs3NzQqHwynqauBO9f5V6wqHw2ppaUka7+npUWtr67BZ+2233abNmzfr9ddf1wUXXOAdD4fD6urqUltbW9L8L67vTOs/NZZq2dnZuvjii1VUVKSKigrNnTtXjzzySNqvrb6+Xi0tLbrsssuUmZmpzMxM1dTU6NFHH1VmZqZCoVBar++LgsGgLrnkEn3wwQdD+neXVkGbnZ2toqIiVVVVeccSiYSqqqoUiURS2NnATJs2TeFwOGld8XhcdXV13roikYja2tpUX1/vzamurlYikVBxcfGQ9/x5ZqbbbrtNmzZtUnV1taZNm5Y0XlRUpKysrKT1NTY2qqmpKWl9e/bsSfqPSWVlpQKBgGbOnDk0C+mDRCKhzs7OtF/bggULtGfPHjU0NHg1f/58rVixwvtzOq/vi44fP67f/e53mjRp0tD+3fXrrbwU2rBhg/n9fnvmmWds//79dsstt1gwGEx6V3A4am9vt927d9vu3btNkv3oRz+y3bt320cffWRmn23vCgaD9uKLL9q7775r119//Rm3d82bN8/q6urszTfftOnTpw+L7V2rV6+2vLw8e+ONN5K20Xz66afenFWrVllhYaFVV1fbrl27LBKJWCQS8cZPbaNZuHChNTQ02NatW23ixInDYovQPffcYzU1NXbo0CF799137Z577jGfz2evvfaamaX32s7k87sOzNJ7fWvWrLE33njDDh06ZG+99ZaVlJRYfn6+tbS0mNnQrS3tgtbM7LHHHrPCwkLLzs62K664wt5+++1Ut/Rnvf766ybptFq5cqWZfbbF695777VQKGR+v98WLFhgjY2NSdc4duyYLV++3MaMGWOBQMBuuukma29vT8Fqkp1pXZLs6aef9uZ0dHTYrbfeauPGjbPc3FxbsmSJHT16NOk6hw8ftsWLF1tOTo7l5+fbmjVrrLu7e4hXc7rvfOc7NnXqVMvOzraJEyfaggULvJA1S++1nckXgzad17ds2TKbNGmSZWdn2/nnn2/Lli2zDz74wBsfqrXxebQA4FhavUYLAOmIoAUAxwhaAHCMoAUAxwhaAHCMoAUAxwhaAHCMoAUAxwhaAHCMoAUAxwhaAHDs/wEDckf0fYKamgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sitk.GetArrayFromImage(p_pred_resampled[:,:,100]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
