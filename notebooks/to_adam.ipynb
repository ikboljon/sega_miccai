{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ikboljonsobirov/.conda/envs/qkv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from monai.losses import DiceLoss, DiceCELoss, FocalLoss, GeneralizedDiceFocalLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai import transforms\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Activations,\n",
    "    Compose,\n",
    ")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.utils.enums import MetricReduction\n",
    "from monai.networks.nets import SwinUNETR, UNet, SegResNet, UNETR\n",
    "from monai import data\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import SimpleITK as sitk\n",
    "from einops import rearrange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datafold_read(datalist, basedir, fold=0, key=\"training\"):\n",
    "    with open(datalist) as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    json_data = json_data[key]\n",
    "\n",
    "    for d in json_data:\n",
    "        for k in d:\n",
    "            if isinstance(d[k], list):\n",
    "                d[k] = [os.path.join(basedir, iv) for iv in d[k]]\n",
    "            elif isinstance(d[k], str):\n",
    "                d[k] = os.path.join(basedir, d[k]) if len(d[k]) > 0 else d[k]\n",
    "\n",
    "    tr = []\n",
    "    val = []\n",
    "    for d in json_data:\n",
    "        if \"fold\" in d and d[\"fold\"] == fold:\n",
    "            val.append(d)\n",
    "        else:\n",
    "            tr.append(d)\n",
    "\n",
    "    return tr, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = (192,192,192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadImageTorch:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, path_to_data_dir):\n",
    "        if path_to_data_dir is None:\n",
    "            print('Please provide directory to the data path')\n",
    "        else:\n",
    "            img_data = self.read_torch_file(path_to_data_dir['path'])\n",
    "\n",
    "            return img_data\n",
    "\n",
    "            \n",
    "    @staticmethod\n",
    "    def read_torch_file(path):\n",
    "        img = torch.load(path)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(batch_size, sw_batch_size, data_dir, json_list, fold):\n",
    "    data_dir = data_dir\n",
    "    datalist_json = json_list\n",
    "\n",
    "    train_files, validation_files = datafold_read(datalist=datalist_json, basedir=data_dir, fold=fold)\n",
    "    train_transform = transforms.Compose(\n",
    "        [\n",
    "            LoadImageTorch(),\n",
    "            # LoadImagedMonai(keys=[\"image\",\"image2\", \"label\"], ensure_channel_first = True),\n",
    "            # transforms.SpatialPadd(keys=[\"image\", \"label\"], spatial_size=(roi[0], roi[1], roi[2]), method='end'),\n",
    "            transforms.RandCropByPosNegLabeld(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                label_key=\"label\",\n",
    "                spatial_size=roi,\n",
    "                pos=1,\n",
    "                neg=1,\n",
    "                num_samples=1,\n",
    "                image_key=\"image\",\n",
    "                image_threshold=0,\n",
    "            ),\n",
    "            # transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "            # # transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=-1024, a_max=1024, b_min=0.0, b_max=1.0, clip=True),\n",
    "            # # ClipCT(keys=[\"image\"]),\n",
    "\n",
    "            # transforms.RandFlipd(\n",
    "            #     keys=[\"image\", \"label\"],\n",
    "            #     spatial_axis=[0],\n",
    "            #     prob=0.20,\n",
    "            # ),\n",
    "            # transforms.RandFlipd(\n",
    "            #     keys=[\"image\", \"label\"],\n",
    "            #     spatial_axis=[1],\n",
    "            #     prob=0.20,\n",
    "            # ),\n",
    "            # transforms.RandFlipd(\n",
    "            #     keys=[\"image\", \"label\"],\n",
    "            #     spatial_axis=[2],\n",
    "            #     prob=0.20,\n",
    "            # ),\n",
    "            # transforms.RandRotate90d(\n",
    "            #     keys=[\"image\", \"label\"],\n",
    "            #     prob=0.20,\n",
    "            #     max_k=3,\n",
    "            # ),\n",
    "            # transforms.RandShiftIntensityd(\n",
    "            #     keys=[\"image\"],\n",
    "            #     offsets=0.10,\n",
    "            #     prob=0.50,\n",
    "            # ),\n",
    "            # transforms.RandZoomd(   #added new\n",
    "            #     keys=[\"image\", \"label\"],\n",
    "            #     prob = 0.5,\n",
    "            #     min_zoom = 0.85,\n",
    "            #     max_zoom = 1.15,\n",
    "            #     mode = ['area', 'nearest'],\n",
    "            # ),\n",
    "            \n",
    "    \n",
    "            # transforms.RandScaleIntensityd(keys=\"image\", factors=0.1, prob=0.5),\n",
    "            # transforms.RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=0.5),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    val_transform = transforms.Compose(\n",
    "        [\n",
    "            LoadImageTorch(),\n",
    "            # LoadImagedMonai(keys=[\"image\", \"image2\", \"label\"], ensure_channel_first = True),\n",
    "            # transforms.Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "            # # transforms.CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "            # # transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=-1024, a_max=1024, b_min=0.0, b_max=1.0, clip=True),\n",
    "            # transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        ]\n",
    "    )\n",
    "    train_ds = data.Dataset(data=train_files, transform=train_transform)\n",
    "\n",
    "\n",
    "    train_loader = data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    val_ds = data.Dataset(data=validation_files, transform=val_transform)\n",
    "\n",
    "    val_loader = data.DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"\"\n",
    "\n",
    "\n",
    "data_dir = '/share/nvmedata/ikboljonsobirov/fusion_vit/hecktor2022_torch/'\n",
    "datalist_json = '/home/ikboljonsobirov/hecktor/fusion_vit/fusion_vit_project/files/train_json_torch.json'\n",
    "batch_size = 1\n",
    "sw_batch_size = 1\n",
    "fold = 0 # 0,1,2,3,4\n",
    "# roi = (64,64,64)\n",
    "infer_overlap = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, train_ds, val_ds = get_loader(batch_size, sw_batch_size, data_dir, datalist_json, fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(metatensor([0., 1.]), torch.Size([1, 2, 200, 200, 310]), ['CHUV-008'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(a['seg']), a['ctpt'].shape, a['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qkv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
