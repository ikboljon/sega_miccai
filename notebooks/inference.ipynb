{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ikboljonsobirov/hecktor/fusion_vit/fusion_vit_project\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ikboljonsobirov/.conda/envs/sega/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.data.components.sega_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/ikboljonsobirov/hecktor/fusion_vit/fusion_vit_project/notebooks/inference.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.79/home/ikboljonsobirov/hecktor/fusion_vit/fusion_vit_project/notebooks/inference.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m BaselineUNet, FastSmoothSENormDeepUNet_supervision_skip_no_drop\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.79/home/ikboljonsobirov/hecktor/fusion_vit/fusion_vit_project/notebooks/inference.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msega_module\u001b[39;00m \u001b[39mimport\u001b[39;00m SegaModule\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.79/home/ikboljonsobirov/hecktor/fusion_vit/fusion_vit_project/notebooks/inference.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msega_dataset\u001b[39;00m \u001b[39mimport\u001b[39;00m SegaDataset\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.79/home/ikboljonsobirov/hecktor/fusion_vit/fusion_vit_project/notebooks/inference.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m dice\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.79/home/ikboljonsobirov/hecktor/fusion_vit/fusion_vit_project/notebooks/inference.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m ConcatDataset, DataLoader, Dataset, random_split, Subset\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src.data.components.sega_dataset'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nrrd\n",
    "from einops import  rearrange\n",
    "from monai.networks.nets import UNETR, SwinUNETR, SegResNet\n",
    "\n",
    "from src.models.components.models import BaselineUNet, FastSmoothSENormDeepUNet_supervision_skip_no_drop\n",
    "from src.models.sega_module import SegaModule\n",
    "from src.data.components.sega_dataset import SegaDataset\n",
    "from src.models.components.metrics import dice\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, random_split, Subset\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nifti(path):\n",
    "    \"\"\"Read a NIfTI image. Return a SimpleITK Image.\"\"\"\n",
    "    nifti = sitk.ReadImage(str(path))\n",
    "    return nifti\n",
    "\n",
    "\n",
    "def write_nifti(sitk_img, path):\n",
    "    \"\"\"Save a SimpleITK Image to disk in NRRD format.\"\"\"\n",
    "    writer = sitk.ImageFileWriter()\n",
    "    writer.SetImageIO(\"NrrdImageIO\")\n",
    "    writer.SetFileName(str(path))\n",
    "    writer.Execute(sitk_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = pathlib.Path('/share/sda/nurenzhaksylyk/segaorta_resampled/')\n",
    "\n",
    "chkpt_path = '/home/ikboljonsobirov/hecktor/fusion_vit/fusion_vit_project/logs/train/runs/2023-09-27_21-13-02/checkpoints/epoch_099.ckpt'\n",
    "\n",
    "output_path = pathlib.Path('/home/ikboljonsobirov/lightning-hydra-template/data/sega_val_pred/')\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 12 12\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.data.augmentations import *\n",
    "\n",
    "trans_pred = Compose([\n",
    "                    NormalizeIntensity(),\n",
    "                    ToTensor(), \n",
    "                    Resizing(z=256,x=256,y=256),\n",
    "                    ])\n",
    "\n",
    "trans_orig = Compose([\n",
    "                    NormalizeIntensity(),\n",
    "                    ToTensor(), \n",
    "                    ]) \n",
    "\n",
    "dataset_pred = SegaDataset(data_path, transforms=trans_pred)\n",
    "dataset_orig = SegaDataset(data_path, transforms=trans_orig)\n",
    "\n",
    "\n",
    "full_indices = range(len(dataset_pred))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=786)\n",
    "\n",
    "train_idx = {}\n",
    "test_idx = {}\n",
    "\n",
    "key = 1\n",
    "for i,j in kf.split(full_indices):\n",
    "    train_idx[key] = i\n",
    "    test_idx[key] = j\n",
    "\n",
    "    key += 1\n",
    "\n",
    "_, val_dataset_pred = Subset(dataset_pred, train_idx[1]), Subset(dataset_pred, test_idx[1])\n",
    "_, val_dataset_orig = Subset(dataset_orig, train_idx[1]), Subset(dataset_orig, test_idx[1])\n",
    "\n",
    "print(len(dataset_pred), len(val_dataset_orig), len(val_dataset_pred))\n",
    "\n",
    "\n",
    "\n",
    "pred_loader = DataLoader(\n",
    "            dataset=val_dataset_pred,\n",
    "            batch_size=1,\n",
    "            num_workers=1,\n",
    "            pin_memory=True,\n",
    "            shuffle=False,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "orig_loader = DataLoader(\n",
    "            dataset=val_dataset_orig,\n",
    "            batch_size=1,\n",
    "            num_workers=1,\n",
    "            pin_memory=True,\n",
    "            shuffle=False,\n",
    "            drop_last=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_pred[0]['input'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = next(iter(pred_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_orig = next(iter(orig_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K7']\n",
      "['K7']\n"
     ]
    }
   ],
   "source": [
    "print(data_pred['id'])\n",
    "print(data_orig['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegResNet(\n",
       "  (act_mod): ReLU(inplace=True)\n",
       "  (convInit): Convolution(\n",
       "    (conv): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  )\n",
       "  (down_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Identity()\n",
       "      (1): ResBlock(\n",
       "        (norm1): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (norm1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (norm1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ResBlock(\n",
       "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (4): ResBlock(\n",
       "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (norm1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (norm1): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_samples): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): UpSample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0, 2.0), mode='trilinear')\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): UpSample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0, 2.0), mode='trilinear')\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(16, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): UpSample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0, 2.0), mode='trilinear')\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_final): Sequential(\n",
       "    (0): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Convolution(\n",
       "      (conv): Conv3d(8, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SegResNet(in_channels=1, out_channels=1)\n",
    "\n",
    "checkpoint = torch.load(chkpt_path)\n",
    "state_dict = checkpoint['state_dict']\n",
    "for key in list(state_dict):\n",
    "    state_dict[key.replace(\"model.\", \"\")] = state_dict.pop(key)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dictionary = {}\n",
    "metric_dictionary['id'] = []\n",
    "metric_dictionary['resize_metric'] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     \u001b[39mfor\u001b[39;00m sample, orig \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(pred_loader, orig_loader):\n\u001b[1;32m      4\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m sample[\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m         output \u001b[39m=\u001b[39m model(\u001b[39minput\u001b[39m)\n",
      "File \u001b[0;32m/share/sda/envs/sega/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/share/sda/envs/sega/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/share/sda/envs/sega/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m   1283\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m-> 1284\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1285\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1286\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/share/sda/envs/sega/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/share/sda/envs/sega/lib/python3.9/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[1;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[0;32m/share/sda/envs/sega/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    317\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for sample, orig in zip(pred_loader, orig_loader):\n",
    "\n",
    "        input = sample['input']\n",
    "\n",
    "        output = model(input)\n",
    "\n",
    "        # y_pred = output.float()\n",
    "        y_pred = torch.where(output>0.5, 1, 0).float()\n",
    "        # Upsample back to original size\n",
    "        y_pred = y_pred.squeeze(0)\n",
    "        y_orig = tio.Resize(orig['input'].squeeze().shape, image_interpolation='nearest')(y_pred)\n",
    "        # Save prediction:\n",
    "\n",
    "        \n",
    "        metric_value_rs = dice(y_pred.unsqueeze(0).detach(), sample['target'].detach())\n",
    "        metric_value_or = dice(y_orig.unsqueeze(0).detach(), orig['target'].detach())\n",
    "\n",
    "        metric_dictionary['id'].append(sample['id'][0])\n",
    "        metric_dictionary['resize_metric'].append(metric_value_rs.item())\n",
    "        metric_dictionary['orig_metric'].append(metric_value_or.item())\n",
    "        \n",
    "        print(f\"id: {sample['id'][0]}, metric_rs: {metric_value_rs}, metric_org: {metric_value_or}\")\n",
    "\n",
    "        if not os.path.exists(output_path / sample['id'][0]):\n",
    "            os.makedirs(output_path / sample['id'][0], exist_ok=True)\n",
    "\n",
    "        # write_nifti(sitk.GetImageFromArray(y_pred.squeeze()),  str(output_path / sample['id'][0] / (sample['id'][0] +'_resize.nrrd')))\n",
    "        # write_nifti(sitk.GetImageFromArray(y_orig.squeeze()),  str(output_path / sample['id'][0] / (sample['id'][0] +'.nrrd')))\n",
    "        sitk.WriteImage(sitk.GetImageFromArray(y_orig.squeeze()),  str(output_path / sample['id'][0] / (sample['id'][0] +'.nrrd')), useCompression=True)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
